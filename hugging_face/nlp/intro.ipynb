{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the course from [huggingface](https://huggingface.co/learn/nlp-course/chapter1/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.4.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sentencepiece\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0 if torch.cuda.is_available() else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/home/ydepledt/py_env/hugging_face/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-cased and revision 935ac13 (https://huggingface.co/distilbert/distilbert-base-cased).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/ydepledt/py_env/hugging_face/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "classifier        = pipeline(\"sentiment-analysis\", device=device)\n",
    "feature_extractor = pipeline(\"feature-extraction\", device=device)\n",
    "summery           = pipeline(\"summarization\", device=device)\n",
    "zero_shot         = pipeline(\"zero-shot-classification\", device=device)\n",
    "generation        = pipeline(\"text-generation\", device=device)\n",
    "fill_mask         = pipeline(\"fill-mask\", device=device)\n",
    "translator        = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9598046541213989}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9994558691978455}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9994338154792786}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598046541213989},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classifier(\"I've been waiting for a HuggingFace course my whole life.\"))\n",
    "print(classifier(\"I hate this so much!\"))\n",
    "print(classifier(\"I don't know what I'm doing.\"))\n",
    "classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = feature_extractor(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' In a small coastal village, the annual summer festival was a cherished tradition that brought together people from all walks of life . The event was more than just a celebration; it was a time for the community to reconnect, share stories, and celebrate their collective heritage . The festival also had a philanthropic angle, with proceeds from the event supporting local charities and community projects .'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"In a small coastal village, the annual summer festival was a cherished tradition that brought together people from all walks of life. The festival, held at the height of summer, featured a vibrant array of activities, including local music performances, artisan crafts, and a variety of food stalls offering everything from freshly caught seafood to homemade pastries. The event was more than just a celebration; it was a time for the community to reconnect, share stories, and celebrate their collective heritage. Each year, the festival attracted visitors from neighboring towns and cities, eager to experience the unique charm of the village and its traditions. The highlight of the festival was always the evening fireworks display, which illuminated the night sky and drew awe-inspired gasps from the crowd. Children would run around with colorful glow sticks, while families enjoyed the warmth of summer evenings and the camaraderie of shared experiences. The festival also had a philanthropic angle, with proceeds from the event supporting local charities and community projects. This aspect of the festival helped reinforce the sense of unity and purpose within the village, as residents worked together to ensure its success. Through these efforts, the summer festival became a symbol of the village's spirit and resilience, celebrating both the joys and challenges of life in a close-knit community.\"\n",
    "\n",
    "summery(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'The new library opening was a grand event. The building’s modern architecture was a significant upgrade from the old one. Attendees enjoyed guided tours, book signings, and a special lecture by a renowned author.', 'labels': ['event', 'technology', 'animal'], 'scores': [0.9250767827033997, 0.05805981159210205, 0.016863368451595306]}\n",
      "{'sequence': 'The recent tech conference showcased cutting-edge innovations in artificial intelligence and robotics. Experts discussed advancements in machine learning algorithms and their applications in various industries.', 'labels': ['technology', 'event', 'animal'], 'scores': [0.7567417621612549, 0.2354135811328888, 0.007844643667340279]}\n",
      "{'sequence': 'The local animal shelter organized a pet adoption drive to find homes for stray animals. Volunteers helped with pet care, and many families were excited to adopt their new furry companions.', 'labels': ['event', 'animal', 'technology'], 'scores': [0.5445965528488159, 0.4439634382724762, 0.011439977213740349]}\n"
     ]
    }
   ],
   "source": [
    "text1 = \"The new library opening was a grand event. The building’s modern architecture was a significant upgrade from the old one. Attendees enjoyed guided tours, book signings, and a special lecture by a renowned author.\"\n",
    "text2 = \"The recent tech conference showcased cutting-edge innovations in artificial intelligence and robotics. Experts discussed advancements in machine learning algorithms and their applications in various industries.\"\n",
    "text3 = \"The local animal shelter organized a pet adoption drive to find homes for stray animals. Volunteers helped with pet care, and many families were excited to adopt their new furry companions.\"\n",
    "\n",
    "subjetcs = [\"event\", \"technology\", \"animal\"]\n",
    "\n",
    "print(zero_shot(text1, subjetcs))\n",
    "print(zero_shot(text2, subjetcs))\n",
    "print(zero_shot(text3, subjetcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"In a small coastal village, the knight and maidservant's daughter had to be separated, so they could not only continue to share a home but also go into their first year before moving into their younger years for the first time.\\n\\nEven\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation(\"In a small coastal village, the knight and\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.12043898552656174,\n",
       "  'token': 7597,\n",
       "  'token_str': ' Taliban',\n",
       "  'sequence': 'In a small coastal village, the Taliban attacked the village'},\n",
       " {'score': 0.11088748276233673,\n",
       "  'token': 5496,\n",
       "  'token_str': ' militants',\n",
       "  'sequence': 'In a small coastal village, the militants attacked the village'},\n",
       " {'score': 0.07308471202850342,\n",
       "  'token': 37953,\n",
       "  'token_str': ' bandits',\n",
       "  'sequence': 'In a small coastal village, the bandits attacked the village'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask(f\"In a small coastal village, the <mask> attacked the village\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"It's a beautiful summer morning. I'm going for a walk in the park. The song of birds is nice.\"}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"C'est une belle matinée d'été. Je vais me promener dans le parc. Le chant des oiseaux est agréable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers are Language Models\n",
    "\n",
    "All the Transformer models mentioned above (GPT, BERT, BART, T5, etc.) have been trained as language models. This means they have been trained on large amounts of raw text in a self-supervised fashion. Self-supervised learning is a type of training in which the objective is automatically computed from the inputs of the model. That means that humans are not needed to label the data!\n",
    "\n",
    "This type of model develops a statistical understanding of the language it has been trained on, but it’s not very useful for specific practical tasks. Because of this, the general pretrained model then goes through a process called transfer learning. During this process, the model is fine-tuned in a supervised way — that is, using human-annotated labels — on a given task.\n",
    "\n",
    "An example of a task is predicting the next word in a sentence having read the n previous words. This is called causal language modeling because the output depends on the past and present inputs, but not the future ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "\n",
    "- [Comprendre les Transformers en 10 min](https://www.youtube.com/watch?v=46XbjplgwOw)\n",
    "- [Transformer Neural Networks, ChatGPT's foundation, Clearly Explained!!!](https://www.youtube.com/watch?v=zxQyTK8quyY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging_face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
